# -*- coding: utf-8 -*-
"""Creditcard Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zUvf6WQYNgFHA-fqChbFfrp6W12gEtlA
"""

!pip install pandas scikit-learn kaggle

from google.colab import drive
drive.mount('/content/drive')

# Replace 'path_to_your_file/creditcard.csv' with the actual path you found
file_path = '/content/drive/My Drive/creditcard.csv'
data = pd.read_csv(file_path, on_bad_lines='skip')

# Verify the dataset
print(data.head())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

data_sample = data.sample(frac=0.1, random_state=42)

X_sample = data_sample.drop('Class', axis=1)
y_sample = data_sample['Class']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)

# Train the model on the sampled data
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=50)
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Plot the confusion matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns

# Compute the confusion matrix
cm = confusion_matrix(y_test, predictions)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming y_test and predictions are defined
cm = confusion_matrix(y_test, predictions)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

print(classification_report(y_test, predictions))

# Print the confusion matrix
cm = confusion_matrix(y_test, predictions)
print("Confusion Matrix:")
print(cm)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score

# Accuracy score
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy * 100:.2f}%")